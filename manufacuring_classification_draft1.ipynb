{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2023\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Manufacturing Processes\n",
    "\n",
    "## Problem\n",
    "\n",
    "\n",
    "## Objectives\n",
    "Give ideas to design engineers by visualizing processes. Represent the manufacturing processes as points in 2D space. Examples include drilling, polishing, bending, extrusion est.\n",
    "\n",
    "## Data\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_manufacturing_processes\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_ISO_standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_hyperlinks(url: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts all hyperlinks from a web page and returns them as a list of strings.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    hyperlinks = [a_tag.get('href') for a_tag in soup.find_all('a')]\n",
    "\n",
    "    return hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hyperlinks(hyperlinks: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Filters a list of hyperlinks based on certain criteria.\n",
    "    \"\"\"\n",
    "    # Drop duplicates\n",
    "    valid_hyperlinks = list(set(hyperlinks))\n",
    "\n",
    "    # Drop None values\n",
    "    valid_hyperlinks = [h for h in valid_hyperlinks if h is not None]\n",
    "\n",
    "    # Drop unrelated links\n",
    "    PREFIXES = ['Category:',\n",
    "                'File:',\n",
    "                'Help:',\n",
    "                'Special:',\n",
    "                'Talk:',\n",
    "                'Wikipedia:',\n",
    "                'Main_Page|Portal:',\n",
    "                'List_of']\n",
    "    PATTERN = fr'^/wiki/(?!{\"|\".join(PREFIXES)}).*'\n",
    "    valid_hyperlinks = [h for h in valid_hyperlinks if re.match(PATTERN, h)]\n",
    "\n",
    "    return valid_hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1716 hyperlinks extracted.\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    'https://en.wikipedia.org/wiki/List_of_welding_processes',\n",
    "    'https://en.wikipedia.org/wiki/List_of_manufacturing_processes',\n",
    "    'https://en.wikipedia.org/wiki/Industrial_processes'\n",
    "]\n",
    "\n",
    "# Collect hyperlinks\n",
    "hyperlinks = []\n",
    "for url in urls:\n",
    "    hyperlinks.extend(extract_hyperlinks(url))\n",
    "print(f'{len(hyperlinks)} hyperlinks extracted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111 hyperlinks remain after filtering.\n",
      "Example:  ['/wiki/System_testing', '/wiki/Real_estate_agent', '/wiki/Hunting']\n"
     ]
    }
   ],
   "source": [
    "# Filter hyperlinks\n",
    "hyperlinks = filter_hyperlinks(hyperlinks)\n",
    "print(f'{len(hyperlinks)} hyperlinks remain after filtering.')\n",
    "print('Example: ', random.sample(hyperlinks, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperlinks_to_titles(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converts a wikipedia hyperlinks to wikipedia titles.\"\"\"\n",
    "    return s.str.replace('/wiki/', '').str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperlink</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/wiki/Foundry</td>\n",
       "      <td>Foundry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/wiki/Poultry_farming</td>\n",
       "      <td>Poultry farming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/wiki/Friction_stir_welding</td>\n",
       "      <td>Friction stir welding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/wiki/Car_dealership</td>\n",
       "      <td>Car dealership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/wiki/Lease</td>\n",
       "      <td>Lease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hyperlink                  title\n",
       "0                /wiki/Foundry                Foundry\n",
       "1        /wiki/Poultry_farming        Poultry farming\n",
       "2  /wiki/Friction_stir_welding  Friction stir welding\n",
       "3         /wiki/Car_dealership         Car dealership\n",
       "4                  /wiki/Lease                  Lease"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'hyperlink': pd.Series(hyperlinks),\n",
    "})\n",
    "\n",
    "df['title'] = hyperlinks_to_titles(df['hyperlink'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_dict_search(data: Dict[Any, Any], key: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Recursively searches a nested dictionary for a given key and returns its value. \n",
    "    \"\"\"\n",
    "    for k, v in data.items():\n",
    "        if k == key:\n",
    "            return v\n",
    "        elif isinstance(v, dict):\n",
    "            result = recursive_dict_search(v, key)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def retrieve_summary(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves a summary of a Wikipedia article based on a given article title.\n",
    "    \"\"\"\n",
    "    api_url = f'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&titles={title}&format=json'\n",
    "    response = requests.get(api_url)\n",
    "    try:\n",
    "        json_data = response.json()\n",
    "        summary = recursive_dict_search(json_data['query'], 'extract')\n",
    "    except json.JSONDecodeError:\n",
    "        summary = ''\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['summary'] = df['title'].apply(retrieve_summary)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_summary(summary: str) -> str:\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_count'] = df.clean_summary.str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Obsolete cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Casting',\n",
       " '/wiki/Centrifugal_casting_(industrial)',\n",
       " '/wiki/Continuous_casting',\n",
       " '/wiki/Die_casting',\n",
       " '/wiki/Evaporative-pattern_casting']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_hrefs(hrefs: List[str],\n",
    "                 start_str: str,\n",
    "                 end_str: str,\n",
    "                 starts_with: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract a sublist of hrefs that occur between two specific strings and starts with specific string.\n",
    "    \"\"\"\n",
    "    start_index = hrefs.index(start_str)\n",
    "    end_index = hrefs.index(end_str)\n",
    "    hrefs = hrefs[start_index: end_index + 1]\n",
    "\n",
    "    hrefs = [h for h in hrefs if h.startswith(starts_with)]\n",
    "\n",
    "    return hrefs\n",
    "\n",
    "\n",
    "hrefs = extract_hrefs(url)\n",
    "hrefs = filter_hrefs(hrefs, start_str='/wiki/Casting',\n",
    "                     end_str='/wiki/Bake-out', starts_with='/wiki')\n",
    "hrefs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
